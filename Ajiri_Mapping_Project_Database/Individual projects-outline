1. obtain your data via scraping, regular expressions, CSV files--whatever method that provides you with the data you need.

I scraped the Iran Stock Exchange website in 2 levels:
- first, I scraped the page that had the name of all the companies on the stock exchange market + the url to their individual pages.

- I wrote functions to gothrough all the urls related to banks and petrochemical companies and scraped the list of their shareholders, boardmembers and contact info.

2. write down 1 to 3 central research questions that define what your approach to this data--and how this data can be mapped geographically.

- Where are most of the businesses located in Tehran?
- are different sectors clustered in a specific neighborhood?
- how far/close are different sectors from one another
Other questions that I eventually want to work on (after I mapped all the businesses and their shareholders):
- Which companies have common shareholders?
- which entity/individuals are behind the sahreholders (my hypothesis is that all the big profiting companies in Iran are eventually connected to the government/The Supreme Leader/Revolutionary Guards/Military)

3. build a schema for your database: how many dictionaries/tables will there be? What are the fields that you will use? What fields do you need in order to make aggregations and study the subject? Will there be primary keys, the most important unit of study, that exist the across tables (if you have more than one). Map this out before you build your dictionaries.

- I have four dictionaries:
1. dict of all the companies on the exchange market with their urls
2. dict of all the shareholders of banks and petro companies
3. dict of all the board members of banks and petro companies
4. dict of all the info of banks and petro companies

for the rest of the questions please check the two attached python notebooks.